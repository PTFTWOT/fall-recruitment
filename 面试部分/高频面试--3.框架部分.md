**Hadoop MR & Spark**

- 是否手写MR和Spark
- Hadoop PK Spark <a href = ' https://www.zhihu.com/question/23036370 '>参考链接</a>
  - Hadoop面向磁盘，MR迭代计算、实时计算、交互查询低效
  - Spark面向内存，为多个不同的数据源提供近乎实时的处理性能
- Hadoop 两种版本的区别
  - 1.0
    -  由一个**JobTracker**和若干个**TaskTracker**两类服务组成
    - 其中JobTracker负责**资源管理和所有作业的控制**，TaskTracker负责接收来自JobTracker的**命令并执行它**。
    - 所以MapReduce即是任务**调度框架又是计算**框架
    - 会出现JobTracker任务过重，而且存在**单点故障问题**，并且容易出现OOM问题，资源分配不合理等问题 
  - 2.0
    -  由ResourceManager进行资源管理调度，有ApplicationMaster进行任务管理和任务监控
    -  增加了standbynamenode进行**热备份**，解决了1.0的单点故障问题
    - 由NodeManager替代TaskTracker进行具体任务的执行，所以**MapReduce只是一个计算**框架，具体**资源调度全部交给Yarn**框架 
- MR原理 <a href = ' https://zhuanlan.zhihu.com/p/62135686 '>参考链接</a>
  - 是什么
    -  MapReduce是一种分布式计算框架 ，以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。主要用于搜索领域，解决海量数据的计算问题
    -  MR有两个阶段组成：Map和Reduce，用户只需实现map()和reduce()两个函数，即可实现分布式计算
  - 做什么
    - MapReduce框架由Map和Reduce组成
    - Map()负责把一个大的block块进行切片并计算
    - Reduce() 负责把Map()切片的数据进行汇总、计算
  - 怎么做
    - 第一步对输入的数据进行切片，每个切片分配一个map()任务，map()对其中的数据进行计算，对每个数据用键值对的形式记录，然后输出到环形缓冲区
    - map（）中输出的数据在环形缓冲区内进行快排，每个环形缓冲区默认大小100M，当数据达到80M时（默认），把数据输出到磁盘上。形成很多个内部有序整体无序的小文件
    - 框架把磁盘中的小文件传到Reduce()中来，然后进行归并排序，最终输出
  - 要点
    - MapReduce将输入的数据进行逻辑切片，一片对应一个Map任务
    - Map以并行的方式处理切片
    - 框架对Map输出进行排序，然后发给Reduce
    - MapReduce的输入输出数据处于同一个文件系统（HDFS）
    - 框架负责任务调度、任务监控、失败任务的重新执行
    - 框架会对键和值进行序列化，因此键和值需要实现writable接口，框架会对键排序，因此必须实现writableComparable接口
- spark 提交作业[执行流程](https://www.cnblogs.com/frankdeng/p/9301485.html)
- NameNode有什么作用
  - 是master节点的主节点，可以看作是分布式文件系统中的管理者
  - 主要负责管理文件系统的名命空间、集群配置信息和存储块的复制等
  - 将文件系统的元数据（文件信息、文件对应文件块的信息、每个文件块在DataNode的信息）存储在内存中
- spark submit脚本有哪些参数
- yarn模式有哪些，谁快？

**Hive**

- [HiveQL执行过程](https://note.youdao.com/ynoteshare1/index.html?id=352829ceba3fe8181be1e10e714d1e72)
- Hive 与Hadoop 关系
- Hive使用经验
- hive常用参数

实时处理

- flink 如何保证数据完整性
- 其它实时处理框架