**Hadoop MR & Spark**

- 是否手写MR和Spark
- **Hadoop PK Spark <a href = ' https://www.zhihu.com/question/23036370 '>参考链接</a>**
  - Hadoop面向磁盘，MR迭代计算、实时计算、交互查询低效
  - Spark面向内存，为多个不同的数据源提供近乎实时的处理性能
- **Hadoop 两种版本的区别**
  - 1.0
    -  由一个**JobTracker**和若干个**TaskTracker**两类服务组成
    - 其中JobTracker负责**资源管理和所有作业的控制**，TaskTracker负责接收来自JobTracker的**命令并执行它**。
    - 所以MapReduce即是任务**调度框架又是计算**框架
    - 会出现JobTracker任务过重，而且存在**单点故障问题**，并且容易出现OOM问题，资源分配不合理等问题 
  - 2.0
    -  由ResourceManager进行资源管理调度，有ApplicationMaster进行任务管理和任务监控
    -  增加了standbynamenode进行**热备份**，解决了1.0的单点故障问题
    - 由NodeManager替代TaskTracker进行具体任务的执行，所以**MapReduce只是一个计算**框架，具体**资源调度全部交给Yarn**框架 
- **MR原理 <a href = ' https://zhuanlan.zhihu.com/p/62135686 '>参考链接</a>**
  - 是什么
    -  MapReduce是一种分布式计算框架 ，以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。主要用于搜索领域，解决海量数据的计算问题
    -  MR有两个阶段组成：Map和Reduce，用户只需实现map()和reduce()两个函数，即可实现分布式计算
  - 做什么
    - MapReduce框架由Map和Reduce组成
    - Map()负责把一个大的block块进行切片并计算
    - Reduce() 负责把Map()切片的数据进行汇总、计算
  - 怎么做
    - 第一步对输入的数据进行切片，每个切片分配一个map()任务，map()对其中的数据进行计算，对每个数据用键值对的形式记录，然后输出到环形缓冲区
    - map（）中输出的数据在环形缓冲区内进行快排，每个环形缓冲区默认大小100M，当数据达到80M时（默认），把数据输出到磁盘上。形成很多个内部有序整体无序的小文件
    - 框架把磁盘中的小文件传到Reduce()中来，然后进行归并排序，最终输出
  - 要点
    - MapReduce将输入的数据进行逻辑切片，一片对应一个Map任务
    - Map以并行的方式处理切片
    - 框架对Map输出进行排序，然后发给Reduce
    - MapReduce的输入输出数据处于同一个文件系统（HDFS）
    - 框架负责任务调度、任务监控、失败任务的重新执行
    - 框架会对键和值进行序列化，因此键和值需要实现writable接口，框架会对键排序，因此必须实现writableComparable接口

Spark

- spark 提交作业[执行流程](https://www.cnblogs.com/frankdeng/p/9301485.html)

  -  构建Spark Application的运行环境（**启动SparkContext**），SparkContext向资源管理器（可以是Standalone、Mesos或YARN）**注册并申请**运行**Executor资源** 
  -  资源管理器分配Executor**资源并启动**StandaloneExecutorBackend，Executor**运行情况将随着心跳**发送到资源管理器上 
  -  SparkContext构建成DAG图，将DAG图**分解成Stage**，并把Taskset发送给Task Scheduler。Executor向SparkContext**申请Task** 
  -  Task Scheduler**将Task发放给Executor运行**同时SparkContext将**应用程序代码发放给Executor**
  -  **Task在Executor上运行**，运行完毕释放所有资源

- Spark 运行特点

  -  每个Application获取专属的executor进程，该进程在Application期间一直驻留，并以多线程方式运行tasks 
  -  这种Application隔离机制有其优势的，无论是从调度角度看（每个Driver调度它自己的任务），还是从运行角度看（来自不同Application的Task运行在不同的JVM中）
  - 这也意味着Spark Application不能跨应用程序共享数据，除非将数据写入到外部存储系统
  -  Spark与资源管理器无关，只要能够获取executor进程，并能保持相互通信就可以 
  -  提交SparkContext的Client应该靠近Worker节点（运行Executor的节点)，最好是在同一个Rack里 ； 运行过程中SparkContext和Executor之间有大量的信息交换 ； 不要远离Worker运行SparkContext （**移动计算而不是移动数据**）

- **job、stage、task**

  -  Job=多个stage，Stage=多个同种task
  -  Task分为ShuffleMapTask和ResultTask，Dependency分为ShuffleDependency和NarrowDependency 
  -  划分Stage的依据是RDD之间的依赖关系 
  -  Job：    包含多个Task组成的并行计算，是由Action行为触发的 
  -  Stage：每个Job会被拆分很多组Task，作为一个TaskSet，其名称为Stage 
  -  Task：  在Executor进程中执行任务的工作单元，多个Task组成一个Stage ，一个RDD的partition数对应task数

- 宽窄依赖

  - 父RDD--子RDD ：一对一窄依赖（不改变partition数），一对多宽依赖（有shuffle)

  - spark 容错机制

    - 线性容错：一个RDD出错，可从它的父RDD重新计算所得，代价小
    - 物化容错：宽依赖有shuffle，代价大，物化备用

  - 划分规则

    1.从后向前推理，遇到宽依赖就断开，遇到窄依赖就把当前的RDD加入到Stage中；

    2.每个Stage里面的Task的数量是由该Stage中最后 一个RDD的Partition数量决定的；

    3.最后一个Stage里面的任务的类型是ResultTask，前面所有其他Stage里面的任务类型都是ShuffleMapTask；

    4.代表当前Stage的算子一定是该Stage的最后一个计算步骤；

    总结：由于spark中stage的划分是根据shuffle来划分的，而宽依赖必然有shuffle过程，因此可以说spark是根据宽窄依赖来划分stage的。

- spark submit脚本有哪些参数

- yarn模式有哪些，谁快？

HDFS

- NameNode有什么作用
  - 是master节点的主节点，可以看作是分布式文件系统中的管理者
  - 主要负责管理文件系统的名命空间、集群配置信息和存储块的复制等
  - 将文件系统的元数据（文件信息、文件对应文件块的信息、每个文件块在DataNode的信息）存储在内存中

- **HDFS读写过程**
  - 写
    -  用户向Client（客户机）提出请求。例如，需要写入200MB的数据 
    -  Client制定计划：将数据按照64MB为块，进行切割；所有的块都保存三份 
    -  Client将大文件切分成块（block）
    -  针对第一个块，Client告诉NameNode，请帮助我，将64MB的块复制三份 
    - NameNode告诉 client三个数据节点的地址，并将他们根据到client的距离排序
    -  Client把数据和清单发给第一个DataNode
    - 第一个告诉第二个
    - 第二个告诉第三个
    - 某个块写入完成就反馈给NameNode
    - 对其它的块依次执行上述过程，直到所有块都完成后，关闭文件，NameNode将数据持久化到磁盘
  - 读
    -  用户向Client提出读取请求
    -  Client向NameNode请求这个文件的所有信息 
    -  NameNode将给Client这个文件的块列表，以及存储各个块的数据节点清单（按照和客户端的距离排序 ）
    -  Client从距离最近的数据节点下载所需的块 

**Hive**

- [HiveQL执行过程](https://note.youdao.com/ynoteshare1/index.html?id=352829ceba3fe8181be1e10e714d1e72)
- Hive 与Hadoop 关系
- Hive使用经验
- hive常用参数

实时处理

- flink 如何保证数据完整性
- 其它实时处理框架