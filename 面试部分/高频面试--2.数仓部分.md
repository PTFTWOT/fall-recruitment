# **数仓介绍**

- 什么是数仓/对数仓的理解
  - 数仓，顾名思义就是数据的仓库，就是为了管控好海量的数据。
  - 随着数据量的不断增加，数据的开发、使用和维护变得越来越困难，此时就需要一种技术将数据及开发使用维护管控起来，做到规范化、系统化、平台化
  - **数仓主要分为两个部分，一部分是数据，是数仓的价值所在；另一部分就是数据管控手段，包括元数据管理、数据质量管理等**
  - 对数据有序和有结构的分类组织和存储，避免重复建设和数据不一致性，保证数据的规范性
- 什么是粉条数仓/是什么业务
  - 粉条业务主要是针对直播和作品的推广的实现增加曝光及涨粉的一种形式，主要业务以推广订单和财务现金流为主。

# **数仓模型**

- **指标和维度大致介绍**
  - 小爱
    - 小爱数仓主要是围绕小爱这款产品来分析用户，提升日活
    - 一类关键的维度包括设备信息如硬件型号（手机、音箱等），产品信息如MIAI版本、MIUI版本
    - 还有一类维度是从产品使用角度分析，比如domain、category，以及各种新推出的产品相关的维度
    - 指标主要还是看用户的uv、pv、留存，以及对应的各种环比、同比、占比等比率型指标
  - 粉条
    - 用户类：内外部类型、新用户、粉丝档、年龄段、性别、快手用户类型、消费等级、用户分层
    - 来源类：订单来源、广告来源、直播来源、方式（样式类型、app、页面类型、进入方式）、渠道类型、推广类型、业务类型、推广意图、是否 H5、
    - 订单类：支付方式、钱包类型、购买类型（帮/自）、计费类型、订单状态、挂购物车、出价、投放类型、审核拒绝类型、新收银台、退款原因、曝光系数、订单推广类型
    - 设备类：机型、版本号、网络、手机类型
    - id类：直播页面ID、直播间ID、视频作品id，支付者id，访客id，设备id，账户id，计划id， 单元id，创意id
    - 投放类：定向类型、
    - 直播类：直播类型、主播类型、直播卖货、游戏直播、新直播、直播退出类型、直播扣费状态、直播位置
- **有哪些主题**
  - **怎么划分主题**
    - 小爱数仓早期是根据维护的dashboard数据以及各种业务方分析需求总结出的主题，包括用户分析、流量分析、行为分析、各类终端分析、商业化分析
    - 随着数仓的不断完善，后面将主题重新调整为**核心看板、数据分析**和**指标开发**
      - 核心流量是小爱整体核心指标，是从整体的角度来看小爱的发展情况
      - 数据分析主要由数据分析师提出各种分析方法，由我们进行相应的数据建模，包括用户分层（用户分析），日活拆解（流量分析），活动复盘（活动分析）等
      - 指标开发主要是承接各业务方所开发业务的各项指标看板开发
    - 新分类的三种主题下都包含了**用户分析、流量分析、行为分析**等，终端分析和商业化分析整体情况分到核心看板中，具体业务则归纳到指标开发中
  - 粉条主题：**常规订单、直播订单、客户、APP渠道、流量效果转化、财务**
- 数据域介绍
  - 小爱没有数据域这个概念，整体业务相对较为单一，主要是对**用户和小爱交互的行为日志**进行分析，不涉及到其他更多的数据域
  - 域的划分
    - **业务域：粉条**
    - **数据域：流量域、交易域**
      - 数据域面向业务分析，将业务过程或者维度进行抽象的集合
      - 业务过程为不可拆分的行为事件
      - 总线矩阵：明确每个数据域下的业务过程，数据域 + 业务过程 + 维度
- 对数仓建模和分层的了解
  - 建模方式
    - **维度建模：星型模型**
      - 事实表与维度表有什么联系和区别
      - **星型模型由一个事实表和一组维表组成**
      - 每个维表都有一个维作为主键
      - 所有这些维的主键组合成事实表的主键
      - 强调对维度进行预处理，将多个维度集合到一个事实表，形成一个宽表
        - 大宽表一般都是事实表，包含了维度关联的主键和一些度量信息
        - 使用时通过join组合数据
    - 关系建模：雪花模型
      - 用实体加关系描述的数据模型，描述企业的业务架构，再范式理论上符合3NF，面向主题抽象而非业务过程
  - **主要采用了维度建模，一开始建立数仓时对小爱的业务并没有全局的把控，因此选择了以维度建模理论为基础**
    - 优点:要求不高，快速上手,快速响应分析需求
    - 从明确关键业务过程开始，再到明确粒度，再到明确维度，最后明确事实
- 数仓分层，各层内容和作用，是否分主题
  - 小爱这边3层：dwd（明细数据）、dws（聚合数据）、ads（指标数据）
  - ODS（Operational Data Store ）操作数据层
  - 清洗怎么做
    - ETL，通过spark任务完成，主要是对中控日志和客户端日志进行清洗得到大宽表（核心字段规范化映射关系，缺失字段值填充，复杂结构字段清洗）
  - CDM（Common data model） = DWD + DWS
  - DWD的作用及设计考虑
    - 明细数据，方便后续各种看板开发和分析。设计上整理业务，选择将重要的字段都清洗出来形成大宽表，方便后续使用
  - 上层应用有哪些
    - 小爱：核心看板、邮件报表
    - 粉条：报表引擎（天玑、星盒、KwaiBI）、业务系统B/C端、垂直业务数据集市（粉条）
- 维度变化：缓慢变化维
  - 重写维度值：不保留历史数据，始终取罪行数据
  - 插入新的维度行：维度值变化前的事实和过去的维度值关联；维度值变化后的事实和当前的维度值关联
  - 添加维度列
- 参与哪层的建设，实践中是如何结合场景进行模型设计
- 如何保证数据质量
  - 开发时：口径统一、任务优化
  - 开发后：横向指标对比监控，及时性监控
- 监控相关，出了问题如何发现
  - 及时性监控
  - 波动监控
- 任务依赖怎样实现
  - 开发时添加任务依赖和数据依赖,保证数据血缘可回溯
- 怎么评估模型是否满足预期

# **具体实践**

- SQL 优化：

  - select:      列裁剪
  - from        尽量原子化操作(复杂逻辑使用中间表的方式)
  - on            限制笛卡尔积查询(两表join时必须要有on子句)
  - where      分区裁剪    &  表连接时尽早过滤数据
  - group by  默认情况下Map阶段同一Key数据分发给一个reduce
    - ​		 当一个key数据过大时就倾斜了
    - ​        (map端部分聚合 + **负载均衡**)
  - order by  要配合使用limit,避免把所有排序结果分发到一个reducer上
  - limit        设置采样参数,避免查询所有记录
  - 设置并行执行
  - [优化](https://app.yinxiang.com/shard/s35/nl/26911816/12eb4e78-edf6-4373-9459-cb13a460493b)
    - 指定列
    - job太多,初始化和启动耗时,map数量不够-->合并
    - 合适的map reduce个数
  - [Hive性能优化--3. SQL优化](https://app.yinxiang.com/shard/s35/nl/26911816/856c9171-9c09-4f2a-8f8e-206e0466b64f)
- order by 与窗口函数排序的区别
  - 具体的案例
- 数据倾斜：[Hive性能优化--4.数据倾斜](https://app.yinxiang.com/shard/s35/nl/26911816/a963c035-6834-4763-ab22-8813f598ad67)
- 重点--》数据设计和业务的理解
  - 数据本身与数据倾斜（<font color = 'blue'>join on</font>）
    - 小表与大表：map join
      - 将其中做连接的小表（全量数据）分发到所有 MapTask 端进行 Join，从 而避免了 reduceTask，前提要求是内存足以装下该全量数据
    - 大表与大表：空值随机打散  
    - 不同数据类型关联
      - 类型转化，比如都转成字符串
  - 业务本身与数据倾斜（group by）
  - 解决方案：
    - 数据预处理 + 过滤异常值  -->空 key: 子查询过滤  + 函数随机分发
    - 单节点计算转为多节点计算--》count(distinct) <font color = 'red'>group by</font>到多个reducer上
    - 单独计算再汇总 || 维度细化
    - 参数调整（map、 reduce、map端部分聚合 + skewindata、 map join)
      - 生成的查询计划有两个MapReduce任务
      - 在第一个MapReduce中，map的输出结果集合会随机分布到reduce中，每个reduce做部分聚合操作，相同的Group By Key有可能分发到不同的reduce中，从而达到负载均衡的目的
      - 第二个MapReduce任务再根据预处理的数据结果按照Group By Key分布到reduce中（这个过程可以保证相同的Group By Key分布到同一个reduce中），最后完成最终的聚合操作
  - key分布不均
  - group by 维度太小
  - count distinct 特殊值过多

# **其它理论**

**元数据**

- 什么是元数据
  -   **用来描述具体数据/信息的数据/信息**   
  - 技术元数据：存储关于数据仓库体系建设细节的数据
    - 存储信息：例如表名、字段名、字段备注、分区、责任人、文件大小、表类型、生命周期等
    - 运行信息：
      - Hadoop上的job信息、实例名称、输入输出、运行参数、执行时间、优先级等
      - Hive上的SQL内容、查询表名、扫描文件大小等
      - 开发信息：数据开发方式、任务调度时间、上下游依赖、运行节点信息等
      - 质量信息：运行状态、报警信息、质量评分等
  - 业务元数据：记录了从业务角度所关心的数据信息，通常面向产品及运营人员使用
    - 数据信息：维度、字段含义、安全等级、计算逻辑、指标定义等
    - 应用信息：展示平台、应用产品等

**生命周期管理策略**

* 周期性删除
* 彻底删除：临时数据
* 永久保留
* 极限存储
* 冷数据管理
* 增量表merge全量表策略

**内部表与外部表**

- 内部表和外部表及区别
  - 含有external修饰词的为外部表
  - 内部表由Hive自身管理，外部表由HDFS管理
  - 删除，内部表会直接删除元数据及存储数据；外部表仅仅会删除元数据
- 建表与存储

**表的存储格式**

- hive文件分为列式存储和行式存储。
  - 查询满足条件的一整行数据的时候，列存储需要去每个聚集字段找到相应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快
  - 在查询少数几个字段的时候，列存储由于每个字段的数据聚集存储，因此能大大减少读取的数据量。而由于每个字段的数据类型一定是一样的，列式存储可以针对性的设计更好的压缩算法
  -   MapReduce在读取数据的时候需要并行，这就要求压缩后的文件可以**分片**读取   
  - 行列存储对比
    - 行适合查询多列的情况；列适合查询少列或对其进行聚合操作的情况
    - 行数很多且列中的值有很多重复，列式存储可以更高效率的使用压缩存储 
    - 表有很多列，实际使用中往往只是查询少量的列，这样列式存储的IO效率会相对更高    
    - 聚合查询   
  - 存储格式对比
    -   如果仅仅在hive中存储和查询，建议使用<font color = 'red'>ORC</font>格式   
    -   如果在hive中存储，使用**Impala**查询，建议使用<font color = 'red'>Parquet</font>   
  - hive VS impala
    -  **Impala是基于Hive的大数据实时分析查询引擎** 
    - 执行计划
      - 一棵完整的执行计划树，更好并发和不必要的中间shuffle；
      - map-reduce模式，存在中间结果的落地
    - 数据流
      - 拉--流式，交互式查询
      - 推--批式
    - 内存
      - 内存放不下直接报错，不用外存
      - 使用外存保证顺序执行，中间结果落地
    - 调度
      - 自己完成，simple-schedule，扫描数据的进程尽量靠近数据所在的物理机器
      - Hadoop调度策略
    - 容错
      - 没有容错逻辑，错误就返回，整体容错较好，查询失败再查一次
      - 依赖Hadoop容错能力
    - 适用面
      - 实时，不支持UDF，配合hive
      - 批量复杂查询，数据转换等
- 各种格式介绍
  - textfile（hive 默认）
    - 行式 , 文本格式 ， 空间利用率低 ,  大部分压缩文件不支持分割和并行处理   
  - sequencefile
    - 行式 ,   key/value对的二进制存储格式   ,块压缩效率高
  - rcfile
    - 将表分为几个**行组**，对每个行组内的数据进行**列式**存储   
  - orcfile
    - rcfile的优化
  - parquet
    - 列式, 二进制, 支持Impala， 建议用snappy压缩   

**拉链表**

**范式**

**OLTP PK OLAP**

- oltp 联机事物处理
  - 主要数据操作：随机读写
  - 实体关系模型：存储数据满足3NF
  - 解决数据的冗余与不一致性问题
- olap 联机分析处理
  - 数据操作：批量读写
  - 不关注一致性，关注数据的整合，及复杂大数据查询和处理的性能

**数仓建模方法论**

- ER模型
- 维度模型
- Data Vault 模型
- Anchor 模型