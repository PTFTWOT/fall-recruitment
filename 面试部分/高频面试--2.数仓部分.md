# **数仓介绍**

- 什么是数仓/对数仓的理解
  - 数仓，顾名思义就是数据的仓库，就是为了管控好海量的数据。
  - 随着数据量的不断增加，数据的开发、使用和维护变得越来越困难，此时就需要一种技术将数据及开发使用维护管控起来，做到规范化、系统化、平台化
  - **数仓主要分为两个部分，一部分是数据，是数仓的价值所在；另一部分就是数据管控手段，包括元数据管理、数据质量管理等**
- 什么是粉条数仓/是什么业务
  - 粉条业务主要是针对直播和作品的推广的实现增加曝光及涨粉的一种形式，主要业务以推广订单和财务现金流为主。

# **数仓模型**

- **指标和维度大致介绍**
  - 小爱
    - 小爱数仓主要是围绕小爱这款产品来分析用户，提升日活
    - 一类关键的维度包括设备信息如硬件型号（手机、音箱等），产品信息如MIAI版本、MIUI版本
    - 还有一类维度是从产品使用角度分析，比如domain、category，以及各种新推出的产品相关的维度
    - 指标主要还是看用户的uv、pv、留存，以及对应的各种环比、同比、占比等比率型指标
  - 粉条
    - 用户类：内外部类型、新用户、粉丝档、年龄段、性别、快手用户类型、消费等级、用户分层
    - 来源类：订单来源、广告来源、直播来源、方式（样式类型、app、页面类型、进入方式）、渠道类型、推广类型、业务类型、推广意图、是否 H5、
    - 订单类：支付方式、钱包类型、购买类型（帮/自）、计费类型、订单状态、挂购物车、出价、投放类型、审核拒绝类型、新收银台、退款原因、曝光系数、订单推广类型
    - 设备类：机型、版本号、网络、手机类型
    - id类：直播页面ID、直播间ID、视频作品id，支付者id，访客id，设备id，账户id，计划id， 单元id，创意id
    - 投放类：定向类型、
    - 直播类：直播类型、主播类型、直播卖货、游戏直播、新直播、直播退出类型、直播扣费状态、直播位置
- **有哪些主题**
  - **怎么划分主题**
    - 小爱数仓早期是根据维护的dashboard数据以及各种业务方分析需求总结出的主题，包括用户分析、流量分析、行为分析、各类终端分析、商业化分析
    - 随着数仓的不断完善，后面将主题重新调整为**核心看板、数据分析**和**指标开发**
      - 核心流量是小爱整体核心指标，是从整体的角度来看小爱的发展情况
      - 数据分析主要由数据分析师提出各种分析方法，由我们进行相应的数据建模，包括用户分层（用户分析），日活拆解（流量分析），活动复盘（活动分析）等
      - 指标开发主要是承接各业务方所开发业务的各项指标看板开发
    - 新分类的三种主题下都包含了**用户分析、流量分析、行为分析**等，终端分析和商业化分析整体情况分到核心看板中，具体业务则归纳到指标开发中
  - 粉条主题：**常规订单、直播订单、客户、APP渠道、流量效果转化、财务**
- 数据域介绍
  - 小爱没有数据域这个概念，整体业务相对较为单一，主要是对**用户和小爱交互的行为日志**进行分析，不涉及到其他更多的数据域
  - 域的划分
    - **业务域：粉条**
    - **数据域：流量域、交易域**
- 对数仓建模和分层的了解
  - 建模方式
    - **维度建模：星型模型**
      - 事实表与维度表有什么联系和区别
      - **星型模型由一个事实表和一组维表组成**
      - 每个维表都有一个维作为主键
      - 所有这些维的主键组合成事实表的主键
      - 强调对维度进行预处理，将多个维度集合到一个事实表，形成一个宽表
        - 大宽表一般都是事实表，包含了维度关联的主键和一些度量信息
        - 使用时通过join组合数据
    - 关系建模：雪花模型
      - 用实体加关系描述的数据模型，描述企业的业务架构，再范式理论上符合3NF，面向主题抽象而非业务过程
  - **主要采用了维度建模，一开始建立数仓时对小爱的业务并没有全局的把控，因此选择了以维度建模理论为基础**
    - 优点:要求不高，快速上手,快速响应分析需求
    - 从明确关键业务过程开始，再到明确粒度，再到明确维度，最后明确事实
- 数仓分层，各层内容和作用，是否分主题
  - 小爱这边3层：dwd（明细数据）、dws（聚合数据）、ads（指标数据）
  - 清洗怎么做
    - ETL，通过spark任务完成，主要是对中控日志和客户端日志进行清洗得到大宽表（核心字段规范化映射关系，缺失字段值填充，复杂结构字段清洗）
  - DWD的作用及设计考虑
    - 明细数据，方便后续各种看板开发和分析。设计上整理业务，选择将重要的字段都清洗出来形成大宽表，方便后续使用
  - 上层应用有哪些
    - 小爱：核心看板、邮件报表
    - 粉条：报表引擎（天玑、星盒、KwaiBI）、业务系统B/C端、垂直业务数据集市（粉条）
- 参与哪层的建设，实践中是如何结合场景进行模型设计
- 如何保证数据质量
  - 开发时：口径统一、任务优化
  - 开发后：横向指标对比监控，及时性监控
- 监控相关，出了问题如何发现
  - 及时性监控
  - 波动监控
- 任务依赖怎样实现
  - 开发时添加任务依赖和数据依赖,保证数据血缘可回溯
- 怎么评估模型是否满足预期

# **具体实践**

- SQL 优化：

  - select:      列裁剪
  - from        尽量原子化操作(复杂逻辑使用中间表的方式)
  - on            限制笛卡尔积查询(两表join时必须要有on子句)
  - where      分区裁剪    &  表连接时尽早过滤数据
  - group by  默认情况下Map阶段同一Key数据分发给一个reduce
    - ​		 当一个key数据过大时就倾斜了
    - ​        (map端部分聚合 + **负载均衡**)
  - order by  要配合使用limit,避免把所有排序结果分发到一个reducer上
  - limit        设置采样参数,避免查询所有记录
  - 设置并行执行
  - [优化](https://app.yinxiang.com/shard/s35/nl/26911816/12eb4e78-edf6-4373-9459-cb13a460493b)
    - job太多,初始化和启动耗时,map数量不够-->合并
    - 合适的map reduce个数
    - 指定列
  - 参数设置
  - [Hive性能优化--3. SQL优化](https://app.yinxiang.com/shard/s35/nl/26911816/856c9171-9c09-4f2a-8f8e-206e0466b64f)
  - map join
    - 将其中做连接的小表（全量数据）分发到所有 MapTask 端进行 Join，从 而避免了 reduceTask，前提要求是内存足以装下该全量数据
  - 大表join
  - join介绍
- order by 与窗口函数排序的区别
  - 具体的案例
- 数据倾斜：[Hive性能优化--4.数据倾斜](https://app.yinxiang.com/shard/s35/nl/26911816/a963c035-6834-4763-ab22-8813f598ad67)
- 重点--》数据设计和业务的理解
  - 数据本身与数据倾斜（<font color = 'blue'>join on</font>）
    - 小表与大表：map join
    - 大表与大表：空值随机打散  
    - 不同数据类型关联
      - 类型转化，比如都转成字符串
  - 业务本身与数据倾斜（group by）
  - 解决方案：
    - 数据预处理 + 过滤异常值  -->空 key: 子查询过滤  + 函数随机分发
    - 单节点计算转为多节点计算--》count(distinct) <font color = 'red'>group by</font>到多个reducer上
    - 单独计算再汇总 || 维度细化
    - 参数调整（map、 reduce、map端部分聚合 + skewindata、 map join)
  - key分布不均
  - group by 维度太小
  - count distinct 特殊值过多

# **其它理论**

**元数据**

- 什么是元数据
  -   **用来描述具体数据/信息的数据/信息**   
  - 技术元数据：存储关于数据仓库体系建设细节的数据
    - 存储信息：例如表名、字段名、字段备注、分区、责任人、文件大小、表类型、生命周期等
    - 运行信息：
      - Hadoop上的job信息、实例名称、输入输出、运行参数、执行时间、优先级等
      - Hive上的SQL内容、查询表名、扫描文件大小等
      - 开发信息：数据开发方式、任务调度时间、上下游依赖、运行节点信息等
      - 质量信息：运行状态、报警信息、质量评分等
  - 业务元数据：记录了从业务角度所关心的数据信息，通常面向产品及运营人员使用
    - 数据信息：维度、字段含义、安全等级、计算逻辑、指标定义等
    - 应用信息：展示平台、应用产品等

**内部表与外部表**

- 内部表和外部表及区别
  - 含有external修饰词的为外部表
  - 内部表由Hive自身管理，外部表由HDFS管理
  - 删除，内部表会直接删除元数据及存储数据；外部表仅仅会删除元数据
- 建表与存储

**表的存储格式**

- 有什么区别
- 为什么不用ORC
- 各种格式介绍
- textfile
  -   行式 , 文本格式，可以压缩   ,  大部分压缩文件不支持分割和并行处理   
- sequencefile
  - 行式 ,   key/value对的二进制存储格式   ,块压缩效率高
- rcfile
  -   将表分为几个**行组**，对每个行组内的数据进行**列式**存储   
- orcfile
  - rcfile的优化
- parquet
  - 列式, 二进制, 支持Impala

**拉链表**

**范式**