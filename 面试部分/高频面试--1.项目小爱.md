





# 小爱数仓建设

总结 -- 小爱数仓初期的工作重点在于：

- 业务梳理，架构设计
- 数仓核心任务重构
- 规范制定

背景：最初的小爱数据分为两个部分：dashboard和临时数据支持。

- dashboard展示的是小爱整体及各终端下核心指标数据（包括pv、uv等）
  - 数据产出时间不稳定
  - 新增需求流程复杂：
    - 和前端同学沟通，确定接口格式  
    - 开发接口，方便数据的导入和前端的数据读取
    - 开发spark任务，将数据通过接口导入到数据库中
  - 数据可能出现不一致（不同人开发，没有开发口径文档，无法保证口径一致）
- 临时数据支持则是cover住产品运营同事的各种分析汇报需求
  - 需求很杂很琐碎
  - 需求不明确，需要花很多时间进行沟通确定
  - 有些需求没有相应的dwd或者dws表支持，只能从原始日志中统计
  - 支持较慢，且不成体系

总的来看，最主要的问题在于**数据产出较慢**，其次是**数据质量不高**，很多开发无意义。

改进：

- 重新梳理需求开发流程，重新规范需求的提出，减少不必要的沟通。同时每周对开发的需求进行汇总归档（看需求主要涉及到哪些维度、指标和表）
- 但是，数据孤岛，数据产出不及时，数据不一致问题还是存在，关键在于还是没有系统化管理数据及任务开发。鉴于此，就需要系统整理下小爱各类数据及相应指标，系统化的开发各类需求，保证数据的产出及时，杜绝数据不一致性的出现

数仓开发流程：

1. 首先自然是对小爱业务进行梳理
   - 从dashboard上梳理出小爱最核心的指标
   - 从增长组需求梳理出重要指标
   - 从日常业务需求梳理出各终端需要的维度、指标和表
   - 从数据源出发，分析出重要的原始日志，以及背后的业务逻辑
2. 然后就是根据梳理的业务进行场景划分。由于业务比较单薄，并没有划分数据域，而是直接划分场景主题
   - 早期场景包括用户分析、流量分析、行为分析、终端分析、商业化等
   - 第二期对上述场景进行重新归类，将场景主题分为核心看板、数据分析和指标开发
     - 核心看板：主要是原dashboard上的核心指标数据，也包括上游依赖的明细表和聚合表
     - 数据分析：方便分析师进行增长分析，这一块主要是开发各种dwd大宽表和用户累积表
     - 指标开发：涵盖了各终端核心指标，包括原dashboard上的终端数据，以及体系化的临时需求
3. 接着就是设计数仓架构
   - dw分3层，包括dwd层、dws层、ads层，额外加上dim模块和temp模块
   - 下层的数据源管控（ODS）
   - 上层的数据输出（看板和邮件）
   - 待完善：打点平台、指标体系、报警体系、自动修复体系、元数据管理平台
4. 开发规范制定
   - 命名规范
   - 口径统一
   - 核心字段ETL规则统一
5. 任务重构
   - 从任务稳定性和开发方便性考虑，将原Spark任务重构成HiveSQL任务（只有ETL任务采用Spark作业）
   - 核心任务优化
     - 早期Spark任务优化主要是Spark参数调整和作业中数据结构上的调整，尽量不动任务逻辑
     - 本次是将Spark任务迁移为HiveSQL任务，所以优化方式为：
       - 从数仓分层角度优化任务（构建dwd大宽表、构建更多的dws表）
       - SQL优化（减少重复读取数据、减少shuffle数量，尽量使用with as）
       - hive参数调整（主要是内存大小调整和小文件合并）
     - 早期Spark大作业逐步下线
6. 数仓数据完善
   - 核心看板任务基本完善
   - 分析师提出的各种流量拆解任务（数据输出形式是看板或者邮件）
   - 各终端需求方的业务需求，统一归为指标开发这一类（数据输出形式为看板）

# 小爱数仓质量体系

从2019年12月开始构建数仓到2020年4月份，小爱数仓已经初具规模，日常任务200+，处理数据量级为TB级，核心看板和各终端需求方所需数据均已满足。但是依然存在着问题：

核心任务产出不及时数据不一致数据不够完备失败任务修复麻烦

数仓第二阶段的重点依然是补充数仓中的数据，但是也开始关注数据的质量

- 首当其冲的就是核心数据的产出时间
  - 任务流程一般是dwd -> dws -> ads，dwd耗时2小时，dws耗时1小时，ads任务0.5小时到1.5小时不等。一般来说，核心看板数据是可以在6点前出
  - 但是随着任务越来越多，资源逐渐不够用，核心数据产出时间无法得到保障。
  - 为保证核心任务及时产出，我们的工作主要是：
    - 核心任务单独申请资源
    - 梳理各任务重要性，按优先级分批计算
      - 0点0点30分：启动dwd任务
      - 2点3点：启动核心dws任务
      - 3点4点：启动核心ads任务和非核心dws任务
      - 6点~14点：启动非核心ads任务
    - 核心任务输出定时检测，保证及时发现延时或失败任务，并进行相应的修复
- 然后就是数据的一致性问题
  - 背景：一次修改核心dwd表ETL任务时出错，导致每天清洗出的dwd表有极少的行丢失，但是依然造成数据对不上。后面发现这个问题已经过去一个多月。然后就只能重跑历史数据，因为出错的是最底层且最核心的dwd表，所以需要重新修复的任务非常多，再加上跨度较大，导致修复难度非常大。为了修复这一次错误，我们暂停了手头上的任务，花费了一周多的时间专门做这个数据修复
  - 为避免这种事故的发生，我们做的工作有：
    - 一致性检测任务（不同表中相同指标uv、pv对比检测、每日检测）
    - 核心dwd表对应ETL任务修改必须要进行team review
    - 尽量减少核心dwd表的修改，修改核心dwd表后不回溯
- 接着就是继续完备数仓中的数据，此时核心看板数据基本都有了，需要补充的是用户属性表，用户行为表等用于数据分析的表和各终端新需求
  - 数据分析
  - 指标开发
- 最后是数仓元数据的梳理
  - 做这个的原因是随着任务越来越多，表和任务的管理越来越难
    - 失败任务修复困难
    - 表和任务没法系统管理起来
    - 曾经开发的表可能忘了，从而导致重复开发
  - 为了方便数据开发人员管理好手头上的表和任务，就需要管理好相应的元数据
    - 表链接、任务链接、上下游依赖、数据起始时间、任务调度时间等
    - 然后是对这些任务进一步分类归纳，给每个任务打上多个tag，方便后面快速查找和修复



































































